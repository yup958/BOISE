set.seed(817)
setwd('~/RAwork/BOISE/BOISE_followup/PCBA_CV/')
idxs = sample(1:102)#102
sample_size = 500
id=idxs[1]
load(paste('~/CHTC_Downloads/PCBA/pcba_orig_clust_res_', as.character(id), '.RData',sep=''))
inform_scores = rep(0, ncol(train))
for (i in 1:sample_size) {
for (j in 1:ncol(train)) {
x = train[, j]
complete_idx = which(!is.na(x))
prev_entropy = entropy(cl_sample$CC[i, complete_idx])
active_idx = which(x==1)
inactive_idx = which(x==0)
active_rate = mean(x, na.rm = T)
post_entropy = 0
if(length(active_idx) > 0){
post_entropy = post_entropy + active_rate * entropy(cl_sample$CC[i, active_idx])
}
if(length(inactive_idx) > 0){
post_entropy = post_entropy + (1-active_rate) * entropy(cl_sample$CC[i, inactive_idx])
}
mutual_info = prev_entropy - post_entropy
inform_scores[j] = inform_scores[j] + mutual_info
}
}
#       post_entropy = post_entropy + active_rate * entropy(cl_sample$CC[i, active_idx])
#     }
#     if(length(inactive_idx) > 0){
#       post_entropy = post_entropy + (1-active_rate) * entropy(cl_sample$CC[i, inactive_idx])
#     }
#     mutual_info = prev_entropy - post_entropy
#     inform_scores[j] = inform_scores[j] + mutual_info
#   }
# }
# tmp_inform_entropy = order(inform_scores, decreasing = T)[1:nA]
a = rep(mean(train, na.rm = T), ncol(train))
b = 1 - a
P = clust_sum(cl_sample,train,sample_size, a, b)
nA=1000
inform = order(inform_scores, decreasing = T)[1:nA]
truncated_test = test[which(names(test)%in%colnames(train))]
xA = truncated_test[inform]
ncol(train)
xA=test[inform]
post_adj_mat = matrix(0, sample_size, nrow(train) + 1)
for (i in 1:sample_size) {
lp = apply(P[[i]][,1:ncol(train)], 1, function(q){
return(sum(xA * log(q[inform])) + sum((1-xA) * log(1 - q[inform])))
})
lnew = sum(xA * log(a[inform] / (a[inform] + b[inform]))) +
sum((1 - xA) * log(b[inform] / (a[inform] + b[inform])))
lp = c(lp, lnew) # P(xA|i in ck, C, x0)
prob_masses = c(P[[i]][,ncol(train)+1], m0)
log_prob_prior = log(prob_masses / sum(prob_masses)) #P(i in ck|C, x0)
log_prob_prior = log_prob_prior + lp
c = max(log_prob_prior)
log_prob_prior = log_prob_prior - c
log_post_probs = c + log(sum(exp(log_prob_prior))) #P(xA|C, x0)
weights = lp + log_prob_prior - log_post_probs
c = max(weights)
weights = weights - c
weights = exp(weights) / sum(exp(weights))
post_adj_mat[i, nrow(train) + 1] = weights[length(weights)]
post_adj_mat[i, 1:nrow(train)] = sapply(cl_sample$CC[i,], function(c) return(weights[c]))
}
adj_mat = matrix(0, nrow(train), nrow(train))
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
adj_mat[i,j] = sum(cl_sample$CC[,i]==cl_sample$CC[,j])
}
}
adj_mat = adj_mat / sample_size
## add a "fake" target, for unknown new table in CRP
adj_mat = cbind(adj_mat, rep(0, 101))
adj_mat = rbind(adj_mat, c(rep(0, 101), 1))
wt_adj_mat = matrix(0, nrow(train)+1, nrow(train)+1)
for (k in 1:sample_size) {
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
wt_adj_mat[i,j] = wt_adj_mat[i,j] +
(cl_sample$CC[k,i]==cl_sample$CC[k,j]) * post_adj_mat[k, i] ##or [k,j]
}
}
wt_adj_mat[nrow(train)+1, nrow(train)+1] =
wt_adj_mat[nrow(train)+1, nrow(train)+1] + post_adj_mat[k, nrow(train)+1]
}
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 103)
adj_mat = adj_mat[ordering, ordering]
par(mfrow = c(1,2))
image(adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 102)
adj_mat = adj_mat[ordering, ordering]
par(mfrow = c(1,2))
image(adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
wt_adj_mat = wt_adj_mat[ordering, ordering]
image(wt_adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
## unknown target (103) is most similar to PriA-SSB
print(order(post_adj_mat, decreasing = T))
post_adj_mat = colMeans(post_adj_mat)
post_adj_mat = as.matrix(post_adj_mat)
wt_mat = post_adj_mat %*% t(post_adj_mat)
wt_adj_mat = adj_mat * wt_mat
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
order(post_adj_mat, decreasing = T)
id
id=13
### Fast boise
set.seed(817)
sample_size=500
id
load(paste('~/CHTC_Downloads/PCBA/pcba_orig_clust_res_', as.character(id), '.RData',sep=''))
inform_scores = rep(0, ncol(train))
for (i in 1:sample_size) {
for (j in 1:ncol(train)) {
x = train[, j]
complete_idx = which(!is.na(x))
prev_entropy = entropy(cl_sample$CC[i, complete_idx])
active_idx = which(x==1)
inactive_idx = which(x==0)
active_rate = mean(x, na.rm = T)
post_entropy = 0
if(length(active_idx) > 0){
post_entropy = post_entropy + active_rate * entropy(cl_sample$CC[i, active_idx])
}
if(length(inactive_idx) > 0){
post_entropy = post_entropy + (1-active_rate) * entropy(cl_sample$CC[i, inactive_idx])
}
mutual_info = prev_entropy - post_entropy
inform_scores[j] = inform_scores[j] + mutual_info
}
}
#       post_entropy = post_entropy + active_rate * entropy(cl_sample$CC[i, active_idx])
#     }
#     if(length(inactive_idx) > 0){
#       post_entropy = post_entropy + (1-active_rate) * entropy(cl_sample$CC[i, inactive_idx])
#     }
#     mutual_info = prev_entropy - post_entropy
#     inform_scores[j] = inform_scores[j] + mutual_info
#   }
# }
# tmp_inform_entropy = order(inform_scores, decreasing = T)[1:nA]
a = rep(mean(train, na.rm = T), ncol(train))
b = 1 - a
P = clust_sum(cl_sample,train,sample_size, a, b)
nA=1000
inform = order(inform_scores, decreasing = T)[1:nA]
xA=test[inform]
post_adj_mat = matrix(0, sample_size, nrow(train) + 1)
for (i in 1:sample_size) {
lp = apply(P[[i]][,1:ncol(train)], 1, function(q){
return(sum(xA * log(q[inform])) + sum((1-xA) * log(1 - q[inform])))
})
lnew = sum(xA * log(a[inform] / (a[inform] + b[inform]))) +
sum((1 - xA) * log(b[inform] / (a[inform] + b[inform])))
lp = c(lp, lnew) # P(xA|i in ck, C, x0)
prob_masses = c(P[[i]][,ncol(train)+1], m0)
log_prob_prior = log(prob_masses / sum(prob_masses)) #P(i in ck|C, x0)
log_prob_prior = log_prob_prior + lp
c = max(log_prob_prior)
log_prob_prior = log_prob_prior - c
log_post_probs = c + log(sum(exp(log_prob_prior))) #P(xA|C, x0)
weights = lp + log_prob_prior - log_post_probs
c = max(weights)
weights = weights - c
weights = exp(weights) / sum(exp(weights))
post_adj_mat[i, nrow(train) + 1] = weights[length(weights)]
post_adj_mat[i, 1:nrow(train)] = sapply(cl_sample$CC[i,], function(c) return(weights[c]))
}
adj_mat = matrix(0, nrow(train), nrow(train))
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
adj_mat[i,j] = sum(cl_sample$CC[,i]==cl_sample$CC[,j])
}
}
adj_mat = adj_mat / sample_size
## add a "fake" target, for unknown new table in CRP
adj_mat = cbind(adj_mat, rep(0, 101))
adj_mat = rbind(adj_mat, c(rep(0, 101), 1))
wt_adj_mat = matrix(0, nrow(train)+1, nrow(train)+1)
for (k in 1:sample_size) {
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
wt_adj_mat[i,j] = wt_adj_mat[i,j] +
(cl_sample$CC[k,i]==cl_sample$CC[k,j]) * post_adj_mat[k, i] ##or [k,j]
}
}
wt_adj_mat[nrow(train)+1, nrow(train)+1] =
wt_adj_mat[nrow(train)+1, nrow(train)+1] + post_adj_mat[k, nrow(train)+1]
}
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 103)
adj_mat = adj_mat[ordering, ordering]
ordering = c(ordering, 102)
adj_mat = adj_mat[ordering, ordering]
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 103)
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 102)
adj_mat = adj_mat[ordering, ordering]
par(mfrow = c(1,2))
image(adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
wt_adj_mat = wt_adj_mat[ordering, ordering]
image(wt_adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
post_adj_mat = colMeans(post_adj_mat)
post_adj_mat = as.matrix(post_adj_mat)
wt_mat = post_adj_mat %*% t(post_adj_mat)
wt_adj_mat = adj_mat * wt_mat
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 102)
adj_mat = adj_mat[ordering, ordering]
par(mfrow = c(1,2))
image(adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
wt_adj_mat = wt_adj_mat[ordering, ordering]
image(wt_adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
adj_mat = matrix(0, nrow(train), nrow(train))
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
adj_mat[i,j] = sum(cl_sample$CC[,i]==cl_sample$CC[,j])
}
}
adj_mat = adj_mat / sample_size
## add a "fake" target, for unknown new table in CRP
adj_mat = cbind(adj_mat, rep(0, 101))
adj_mat = rbind(adj_mat, c(rep(0, 101), 1))
wt_mat = post_adj_mat %*% t(post_adj_mat)
wt_adj_mat = adj_mat * wt_mat
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 102)
adj_mat = adj_mat[ordering, ordering]
par(mfrow = c(1,2))
image(adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
wt_adj_mat = wt_adj_mat[ordering, ordering]
image(wt_adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
post_adj_mat = colMeans(post_adj_mat)
post_adj_mat = as.matrix(post_adj_mat)
wt_mat = post_adj_mat %*% t(post_adj_mat)
wt_adj_mat = adj_mat * wt_mat
post_adj_mat
post_adj_mat = matrix(0, sample_size, nrow(train) + 1)
for (i in 1:sample_size) {
lp = apply(P[[i]][,1:ncol(train)], 1, function(q){
return(sum(xA * log(q[inform])) + sum((1-xA) * log(1 - q[inform])))
})
lnew = sum(xA * log(a[inform] / (a[inform] + b[inform]))) +
sum((1 - xA) * log(b[inform] / (a[inform] + b[inform])))
lp = c(lp, lnew) # P(xA|i in ck, C, x0)
prob_masses = c(P[[i]][,ncol(train)+1], m0)
log_prob_prior = log(prob_masses / sum(prob_masses)) #P(i in ck|C, x0)
log_prob_prior = log_prob_prior + lp
c = max(log_prob_prior)
log_prob_prior = log_prob_prior - c
log_post_probs = c + log(sum(exp(log_prob_prior))) #P(xA|C, x0)
weights = lp + log_prob_prior - log_post_probs
c = max(weights)
weights = weights - c
weights = exp(weights) / sum(exp(weights))
post_adj_mat[i, nrow(train) + 1] = weights[length(weights)]
post_adj_mat[i, 1:nrow(train)] = sapply(cl_sample$CC[i,], function(c) return(weights[c]))
}
post_adj_mat = colMeans(post_adj_mat)
post_adj_mat = as.matrix(post_adj_mat)
wt_mat = post_adj_mat %*% t(post_adj_mat)
wt_adj_mat = adj_mat * wt_mat
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
ordering
wt_adj_mat = wt_adj_mat[ordering, ordering]
image(wt_adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
nA
inform = order(inform_scores, decreasing = T)[1:nA]
xA=test[inform]
post_adj_mat = matrix(0, sample_size, nrow(train) + 1)
for (i in 1:sample_size) {
lp = apply(P[[i]][,1:ncol(train)], 1, function(q){
return(sum(xA * log(q[inform])) + sum((1-xA) * log(1 - q[inform])))
})
lnew = sum(xA * log(a[inform] / (a[inform] + b[inform]))) +
sum((1 - xA) * log(b[inform] / (a[inform] + b[inform])))
lp = c(lp, lnew) # P(xA|i in ck, C, x0)
prob_masses = c(P[[i]][,ncol(train)+1], m0)
log_prob_prior = log(prob_masses / sum(prob_masses)) #P(i in ck|C, x0)
log_prob_prior = log_prob_prior + lp
c = max(log_prob_prior)
log_prob_prior = log_prob_prior - c
log_post_probs = c + log(sum(exp(log_prob_prior))) #P(xA|C, x0)
weights = lp + log_prob_prior - log_post_probs
c = max(weights)
weights = weights - c
weights = exp(weights) / sum(exp(weights))
post_adj_mat[i, nrow(train) + 1] = weights[length(weights)]
post_adj_mat[i, 1:nrow(train)] = sapply(cl_sample$CC[i,], function(c) return(weights[c]))
}
adj_mat = matrix(0, nrow(train), nrow(train))
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
adj_mat[i,j] = sum(cl_sample$CC[,i]==cl_sample$CC[,j])
}
}
adj_mat = adj_mat / sample_size
## add a "fake" target, for unknown new table in CRP
adj_mat = cbind(adj_mat, rep(0, 101))
adj_mat = rbind(adj_mat, c(rep(0, 101), 1))
post_adj_mat = colMeans(post_adj_mat)
order(post_adj_mat, decreasing = T)
post_adj_mat[102]
post_adj_mat[2]
post_adj_mat[14]
post_adj_mat[71]
wt_adj_mat = matrix(0, nrow(train)+1, nrow(train)+1)
for (k in 1:sample_size) {
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
wt_adj_mat[i,j] = wt_adj_mat[i,j] +
(cl_sample$CC[k,i]==cl_sample$CC[k,j]) * post_adj_mat[k, i] ##or [k,j]
}
}
wt_adj_mat[nrow(train)+1, nrow(train)+1] =
wt_adj_mat[nrow(train)+1, nrow(train)+1] + post_adj_mat[k, nrow(train)+1]
}
post_adj_mat = matrix(0, sample_size, nrow(train) + 1)
for (i in 1:sample_size) {
lp = apply(P[[i]][,1:ncol(train)], 1, function(q){
return(sum(xA * log(q[inform])) + sum((1-xA) * log(1 - q[inform])))
})
lnew = sum(xA * log(a[inform] / (a[inform] + b[inform]))) +
sum((1 - xA) * log(b[inform] / (a[inform] + b[inform])))
lp = c(lp, lnew) # P(xA|i in ck, C, x0)
prob_masses = c(P[[i]][,ncol(train)+1], m0)
log_prob_prior = log(prob_masses / sum(prob_masses)) #P(i in ck|C, x0)
log_prob_prior = log_prob_prior + lp
c = max(log_prob_prior)
log_prob_prior = log_prob_prior - c
log_post_probs = c + log(sum(exp(log_prob_prior))) #P(xA|C, x0)
weights = lp + log_prob_prior - log_post_probs
c = max(weights)
weights = weights - c
weights = exp(weights) / sum(exp(weights))
post_adj_mat[i, nrow(train) + 1] = weights[length(weights)]
post_adj_mat[i, 1:nrow(train)] = sapply(cl_sample$CC[i,], function(c) return(weights[c]))
}
wt_adj_mat = matrix(0, nrow(train)+1, nrow(train)+1)
for (k in 1:sample_size) {
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
wt_adj_mat[i,j] = wt_adj_mat[i,j] +
(cl_sample$CC[k,i]==cl_sample$CC[k,j]) * post_adj_mat[k, i] ##or [k,j]
}
}
wt_adj_mat[nrow(train)+1, nrow(train)+1] =
wt_adj_mat[nrow(train)+1, nrow(train)+1] + post_adj_mat[k, nrow(train)+1]
}
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
wt_adj_mat[2,2]
id
wt_adj_mat[102,102]
id
gc()
set.seed(817)
setwd('~/RAwork/BOISE/BOISE_followup/PCBA_CV/')
idxs = sample(1:102)#102
sample_size = 500
id=9
load(paste('~/CHTC_Downloads/PCBA/pcba_orig_clust_res_', as.character(id), '.RData',sep=''))
inform_scores = rep(0, ncol(train))
for (i in 1:sample_size) {
for (j in 1:ncol(train)) {
x = train[, j]
complete_idx = which(!is.na(x))
prev_entropy = entropy(cl_sample$CC[i, complete_idx])
active_idx = which(x==1)
inactive_idx = which(x==0)
active_rate = mean(x, na.rm = T)
post_entropy = 0
if(length(active_idx) > 0){
post_entropy = post_entropy + active_rate * entropy(cl_sample$CC[i, active_idx])
}
if(length(inactive_idx) > 0){
post_entropy = post_entropy + (1-active_rate) * entropy(cl_sample$CC[i, inactive_idx])
}
mutual_info = prev_entropy - post_entropy
inform_scores[j] = inform_scores[j] + mutual_info
}
}
#       post_entropy = post_entropy + active_rate * entropy(cl_sample$CC[i, active_idx])
#     }
#     if(length(inactive_idx) > 0){
#       post_entropy = post_entropy + (1-active_rate) * entropy(cl_sample$CC[i, inactive_idx])
#     }
#     mutual_info = prev_entropy - post_entropy
#     inform_scores[j] = inform_scores[j] + mutual_info
#   }
# }
# tmp_inform_entropy = order(inform_scores, decreasing = T)[1:nA]
a = rep(mean(train, na.rm = T), ncol(train))
b = 1 - a
P = clust_sum(cl_sample,train,sample_size, a, b)
nA
nA=1000
inform = order(inform_scores, decreasing = T)[1:nA]
xA=test[inform]
post_adj_mat = matrix(0, sample_size, nrow(train) + 1)
for (i in 1:sample_size) {
lp = apply(P[[i]][,1:ncol(train)], 1, function(q){
return(sum(xA * log(q[inform])) + sum((1-xA) * log(1 - q[inform])))
})
lnew = sum(xA * log(a[inform] / (a[inform] + b[inform]))) +
sum((1 - xA) * log(b[inform] / (a[inform] + b[inform])))
lp = c(lp, lnew) # P(xA|i in ck, C, x0)
prob_masses = c(P[[i]][,ncol(train)+1], m0)
log_prob_prior = log(prob_masses / sum(prob_masses)) #P(i in ck|C, x0)
log_prob_prior = log_prob_prior + lp
c = max(log_prob_prior)
log_prob_prior = log_prob_prior - c
log_post_probs = c + log(sum(exp(log_prob_prior))) #P(xA|C, x0)
weights = lp + log_prob_prior - log_post_probs
c = max(weights)
weights = weights - c
weights = exp(weights) / sum(exp(weights))
post_adj_mat[i, nrow(train) + 1] = weights[length(weights)]
post_adj_mat[i, 1:nrow(train)] = sapply(cl_sample$CC[i,], function(c) return(weights[c]))
}
adj_mat = matrix(0, nrow(train), nrow(train))
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
adj_mat[i,j] = sum(cl_sample$CC[,i]==cl_sample$CC[,j])
}
}
adj_mat = adj_mat / sample_size
## add a "fake" target, for unknown new table in CRP
adj_mat = cbind(adj_mat, rep(0, 102))
adj_mat = matrix(0, nrow(train), nrow(train))
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
adj_mat[i,j] = sum(cl_sample$CC[,i]==cl_sample$CC[,j])
}
}
adj_mat = adj_mat / sample_size
## add a "fake" target, for unknown new table in CRP
adj_mat = cbind(adj_mat, rep(0, 101))
adj_mat = rbind(adj_mat, c(rep(0, 101), 1))
wt_adj_mat = matrix(0, nrow(train)+1, nrow(train)+1)
for (k in 1:sample_size) {
for (i in 1:nrow(train)) {
for (j in 1:nrow(train)) {
wt_adj_mat[i,j] = wt_adj_mat[i,j] +
(cl_sample$CC[k,i]==cl_sample$CC[k,j]) * post_adj_mat[k, i] ##or [k,j]
}
}
wt_adj_mat[nrow(train)+1, nrow(train)+1] =
wt_adj_mat[nrow(train)+1, nrow(train)+1] + post_adj_mat[k, nrow(train)+1]
}
wt_adj_mat = wt_adj_mat / max(wt_adj_mat)
ordering = c()
for (k in 1:max(cl_sample$CC[1,])) {
ordering = c(ordering, which(cl_sample$CC[1,] == k))
}
ordering = c(ordering, 102)
adj_mat = adj_mat[ordering, ordering]
par(mfrow = c(1,2))
image(adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
wt_adj_mat = wt_adj_mat[ordering, ordering]
image(wt_adj_mat, axes = F, xlab = 'Targets', ylab = 'Targets')
mtext(text=seq(0, 100, 10), side=2, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
mtext(text=seq(0, 100, 10), side=1, line=0.5, at=seq(0, 100, 10) / 103, las=1, cex=1)
gc()
